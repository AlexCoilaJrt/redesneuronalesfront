# PerceptrÃ³n desde Cero: Â¿Tarjeta Platinum?

Este proyecto muestra cÃ³mo funciona un perceptrÃ³n para clasificar si una persona obtiene una tarjeta de crÃ©dito, segÃºn su edad y ahorro.

ğŸ” **Â¿QuÃ© hace?** Entrena un perceptrÃ³n manualmente (desde cero). Compara resultados con scikitâ€‘learn. Visualiza: Zona de decisiÃ³n (quiÃ©n es aprobado o denegado), estructura del perceptrÃ³n y frontera de decisiÃ³n del modelo entrenado.

ğŸ“¦ **Requisitos** AsegÃºrate de tener PythonÂ 3 y estas librerÃ­as:

pip install numpy matplotlib scikitâ€‘learn
â–¶ï¸ CÃ³mo ejecutar Guarda el archivo como perceptron_tarjeta.py y corre:

bash
Copiar
Editar
python perceptron_tarjeta.py
ğŸ“ˆ Â¿QuÃ© vas a ver? Pesos y sesgo aprendidos por el perceptrÃ³n, comparaciÃ³n con el perceptrÃ³n de scikitâ€‘learn, y grÃ¡ficos que muestran clasificaciÃ³n de personas, zona de decisiÃ³n, estructura interna del perceptrÃ³n y lÃ­nea de decisiÃ³n del modelo.

ğŸ“Š Datos de ejemplo Los datos representan personas con diferentes edades y niveles de ahorro. El modelo aprende a decidir si su solicitud de tarjeta es:

âœ… Aprobada
âŒ Denegada

------------------------------------------------

# ğŸ§  Red Neuronal de Hamming para Reconocimiento de Patrones

Este proyecto implementa una **Red Neuronal de Hamming** desde cero en Python, con el objetivo de reconocer patrones binarios (como nÃºmeros 0, 1 y 2 en una matriz de 3x3), incluso si contienen **ruido**.

---

## ğŸ“Œ Â¿QuÃ© hace esta red?

- Compara un patrÃ³n de entrada con patrones aprendidos.
- Encuentra el mÃ¡s **similar** usando la distancia de Hamming.
- Usa una red de competiciÃ³n tipo **Maxnet** para decidir cuÃ¡l patrÃ³n gana.
- Â¡Funciona incluso con ruido aleatorio!

---

## ğŸ”§ Estructura del cÃ³digo

- `RedNeuronalHamming`: clase principal que contiene dos capas:
  - **Capa Hamming**: mide similitud patrÃ³n por patrÃ³n.
  - **Capa Maxnet**: decide cuÃ¡l patrÃ³n es el mÃ¡s parecido.
- Patrones de referencia: 0, 1 y 2 en una matriz 3x3.
- Se puede agregar **ruido** y hacer pruebas interactivas.

---

## ğŸš€ Â¿CÃ³mo usarlo?

1. AsegÃºrate de tener Python 3 y `matplotlib` instalado.
2. Ejecuta el script:


python hamming.py


# ğŸ–¥ï¸ Red Neuronal MNIST: Clasificador de DÃ­gitos Manuscritos

Este proyecto proporciona un **manual de usuario** para ejecutar y entender un script en Python que:

- Carga y visualiza el dataset MNIST.
- Construye, entrena y evalÃºa una red neuronal de una capa oculta con TensorFlow/Keras.
- Muestra la arquitectura de la red como diagrama.
- Grafica la curva de pÃ©rdida y precisiÃ³n durante el entrenamiento.
- Presenta predicciones sobre ejemplos de prueba.
- Genera matriz de confusiÃ³n y reporte de clasificaciÃ³n.

---

## ğŸ“‹ Requisitos

- **PythonÂ 3.7+**
- **TensorFlow 2.x**  
- **Matplotlib**  
- **NumPy**  
- **Seaborn** (opcional, para la matriz de confusiÃ³n)  
- **Scikitâ€‘learn** (para mÃ©tricas)

Instala todo con:
```bash
pip install tensorflow matplotlib numpy seaborn scikit-learn
ğŸš€ Uso
Descarga o clona este repositorio.

Guarda el script como mnist_classifier.py (o el nombre que prefieras).

Desde la terminal, en el directorio del script, ejecuta:

bash
Copiar
Editar
python mnist_classifier.py
ğŸ” Flujo de ejecuciÃ³n
Carga del dataset

Se descargan automÃ¡ticamente los arreglos x_train, y_train, x_test, y_test.

Se imprime en consola la forma de los datos.

VisualizaciÃ³n inicial

Se muestran 12 ejemplos de dÃ­gitos manuscritos con sus etiquetas.

NormalizaciÃ³n y aplanado

Convierte pÃ­xeles de [0,255] a [0.0,1.0].

Aplana cada imagen 28Ã—28 en vectores de longitud 784.

DefiniciÃ³n del modelo

Capa oculta: 128 neuronas con ReLU + Dropout 20%.

Capa de salida: 10 neuronas con Softmax.

VisualizaciÃ³n de la arquitectura

Diagrama estÃ¡tico que muestra las capas y conexiones (simplificado).

ExplicaciÃ³n en consola

Resumen del flujo: entrada â†’ oculta â†’ salida â†’ entrenamiento.

Entrenamiento

Ã‰pocas: 10 (puedes ajustar).

Batch size: 128.

ValidaciÃ³n con 10% de los datos de entrenamiento.

Optimizador: Adam.

PÃ©rdida: sparse_categorical_crossentropy.

EvaluaciÃ³n

PrecisiÃ³n y pÃ©rdida sobre el conjunto de prueba.

Mensaje de valoraciÃ³n segÃºn el porcentaje de acierto.

GrÃ¡ficas de entrenamiento

Curva de pÃ©rdida (entrenamiento vs. validaciÃ³n).

Curva de precisiÃ³n (entrenamiento vs. validaciÃ³n).

PredicciÃ³n de ejemplos

Muestra 10 dÃ­gitos de prueba con etiqueta real y predicciÃ³n.

Matriz de confusiÃ³n y reporte

Heatmap con conteos de verdaderos/falsos positivos.

Informe con precisiÃ³n, recall y F1â€‘score por dÃ­gito.

ğŸ›ï¸ PersonalizaciÃ³n
Ã‰pocas: modifica epochs= en model.fit().

Batch size: ajusta batch_size=.

Dropout: cambia el porcentaje en layers.Dropout().

TamaÃ±o de la capa oculta: varÃ­a layers.Dense(128, ...).

VisualizaciÃ³n: comenta o descomenta secciones plt.show().

ğŸ“Š InterpretaciÃ³n de resultados
PrecisiÃ³n de Test: porcentaje de dÃ­gitos correctamente clasificados.

Curvas de entrenamiento: sirven para detectar sobreajuste/infraajuste.

Matriz de ConfusiÃ³n: identifica dÃ­gitos que el modelo confunde con mÃ¡s frecuencia.

Reporte de clasificaciÃ³n: muestra mÃ©tricas detalladas por clase (0â€“9).

ğŸ› ï¸ SoluciÃ³n de problemas
Si falla la descarga de MNIST, revisa tu conexiÃ³n o actualiza TensorFlow.
